{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading Libraries**"
      ],
      "metadata": {
        "id": "sQf1431p7NrD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7zSNtY546zky"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict, OrderedDict\n",
        "from csv import reader\n",
        "from itertools import chain, combinations\n",
        "from optparse import OptionParser\n",
        "import numpy as np\n",
        "from tabulate import tabulate\n",
        "from google.colab import drive\n",
        "import csv\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define class Node\n",
        "> Represents a node in the FP-tree\n",
        "\n"
      ],
      "metadata": {
        "id": "VlzssaqR7e0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    def __init__(self, itemName, frequency, parentNode):\n",
        "        self.itemName = itemName\n",
        "        self.count = frequency\n",
        "        self.parent = parentNode\n",
        "        self.children = {}\n",
        "        self.next = None\n",
        "\n",
        "    def increment(self, frequency):\n",
        "        self.count += frequency\n",
        "\n",
        "    def display(self, ind=1):\n",
        "        print('  ' * ind, self.itemName, ' ', self.count)\n",
        "        for child in list(self.children.values()):\n",
        "            child.display(ind + 1)\n"
      ],
      "metadata": {
        "id": "2HFEukii7VNq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read from CSV\n",
        "\n",
        "> Adding a function to read file from CSV and try to define whether the file has header file\n",
        "\n"
      ],
      "metadata": {
        "id": "lbWo8etb8OuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_csv_data(filename: str, has_header: bool = False) -> List[List[str]]:\n",
        "    # Mount Google Drive if not already mounted\n",
        "    try:\n",
        "        drive.mount('/content/drive', force_remount=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error mounting Google Drive: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "    # Attempt to read the CSV file\n",
        "    try:\n",
        "        with open(filename, 'r', newline='') as csvfile:\n",
        "            csv_reader = csv.reader(csvfile)\n",
        "            if has_header:\n",
        "                next(csv_reader, None)  # Skip the header row\n",
        "            dataset = []\n",
        "            for row in csv_reader:\n",
        "                # Strip whitespace and filter out empty items\n",
        "                cleaned_row = [item.strip() for item in row if item.strip()]\n",
        "                if cleaned_row:  # Only append non-empty rows\n",
        "                    dataset.append(cleaned_row)\n",
        "            return dataset\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{filename}' not found in Google Drive\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading CSV file: {str(e)}\")\n",
        "        return []\n"
      ],
      "metadata": {
        "id": "aTa9zMjvSEz0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ConstructTree Modified\n",
        "\n",
        "The original headerTable was sorted by frequency in ascending order (reverse=False), but it has been modified to sort in descending order (reverse=True). This change ensures that high-frequency items are prioritized during the construction process."
      ],
      "metadata": {
        "id": "8zffejAfTSH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def constructTree(itemSetList, frequency, minSup):\n",
        "    headerTable = defaultdict(int)\n",
        "    for idx, itemSet in enumerate(itemSetList):\n",
        "        for item in itemSet:\n",
        "            headerTable[item] += frequency[idx]\n",
        "\n",
        "    headerTable = {item: sup for item, sup in headerTable.items() if sup >= minSup}\n",
        "    if not headerTable:\n",
        "        return None, None\n",
        "\n",
        "    headerTable = {item: [freq, None] for item, freq in headerTable.items()}\n",
        "\n",
        "    fpTree = Node('Null', 1, None)\n",
        "\n",
        "    for idx, itemSet in enumerate(itemSetList):\n",
        "        itemSet = [item for item in itemSet if item in headerTable]\n",
        "        itemSet.sort(key=lambda item: (-headerTable[item][0], item))\n",
        "        currentNode = fpTree\n",
        "        for item in itemSet:\n",
        "            currentNode = updateTree(item, currentNode, headerTable, frequency[idx])\n",
        "\n",
        "    return fpTree, headerTable"
      ],
      "metadata": {
        "id": "j81oG9MyTS4x"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions to update Header Table and Tree"
      ],
      "metadata": {
        "id": "TBvGuLHRTyL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def updateHeaderTable(item, targetNode, headerTable):\n",
        "    if(headerTable[item][1] == None):\n",
        "        headerTable[item][1] = targetNode\n",
        "    else:\n",
        "        currentNode = headerTable[item][1]\n",
        "        # Traverse to the last node then link it to the target\n",
        "        while currentNode.next != None:\n",
        "            currentNode = currentNode.next\n",
        "        currentNode.next = targetNode\n",
        "\n",
        "def updateTree(item, treeNode, headerTable, frequency):\n",
        "    if item in treeNode.children:\n",
        "        # If the item already exists, increment the count\n",
        "        treeNode.children[item].increment(frequency)\n",
        "    else:\n",
        "        # Create a new branch\n",
        "        newItemNode = Node(item, frequency, treeNode)\n",
        "        treeNode.children[item] = newItemNode\n",
        "        # Link the new branch to header table\n",
        "        updateHeaderTable(item, newItemNode, headerTable)\n",
        "\n",
        "    return treeNode.children[item]\n",
        "\n",
        "def ascendFPtree(node, prefixPath):\n",
        "    if node.parent != None:\n",
        "        prefixPath.append(node.itemName)\n",
        "        ascendFPtree(node.parent, prefixPath)\n",
        "\n",
        "\n",
        "def getSupport(testSet, itemSetList):\n",
        "    count = 0\n",
        "    for itemSet in itemSetList:\n",
        "        if set(testSet).issubset(itemSet):\n",
        "            count += 1\n",
        "    return count\n",
        "def powerset(s):\n",
        "    return chain.from_iterable(combinations(s, r) for r in range(1, len(s) + 1))\n",
        "def getFrequencyFromList(itemSetList):\n",
        "    return [1] * len(itemSetList)"
      ],
      "metadata": {
        "id": "4SnTEGlkT5AH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MineTree\n",
        "\n",
        "> The mineTree function is responsible for recursively mining frequent patterns from the FP-Tree by constructing conditional FP-Trees for each item in the headerTable. The original recursive logic might not correctly process the conditional FP-Trees, potentially leading to incomplete pattern extraction or infinite recursion if not handled properly.\n",
        "\n"
      ],
      "metadata": {
        "id": "RfWNOBUGVOBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mineTree(headerTable, minSup, preFix, freqItemList, itemSetList):\n",
        "    # Sort the items with frequency and create a list\n",
        "    sortedItemList = [item for item in headerTable.keys()]\n",
        "    sortedItemList.sort(key=lambda item: (headerTable[item][0], item))\n",
        "\n",
        "    # Start with the lowest frequency\n",
        "    for item in sortedItemList:\n",
        "        # Pattern growth is achieved by the concatenation of suffix pattern with frequent patterns generated from conditional FP-tree\n",
        "        newFreqSet = preFix.copy()\n",
        "        newFreqSet.add(item)\n",
        "        support = getSupport(newFreqSet, itemSetList)\n",
        "        # Define the range and the minSup's relationship\n",
        "        if support >= minSup:\n",
        "            freqItemList.append(newFreqSet)\n",
        "        # Find all prefix path, constrcut conditional pattern base\n",
        "        conditionalPattBase, frequency = findPrefixPath(item, headerTable)\n",
        "        # Construct conditonal FP Tree with conditional pattern base\n",
        "        conditionalTree, newHeaderTable = constructTree(conditionalPattBase, frequency, minSup)\n",
        "\n",
        "        if newHeaderTable is not None:\n",
        "            # Mining recursively on the tree\n",
        "            mineTree(newHeaderTable, minSup, newFreqSet, freqItemList, itemSetList)"
      ],
      "metadata": {
        "id": "yvb9NqoPVfhV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FindPrefixPath\n",
        "The original ascendFPtree function included the current node in the prefix path. So we need to modify it to only record the nodes above the current node (using prefixPath[1:])\n"
      ],
      "metadata": {
        "id": "dsjIY9ekS4MC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def findPrefixPath(basePat, headerTable):\n",
        "    # First node in linked list\n",
        "    treeNode = headerTable[basePat][1]\n",
        "    condPats = []\n",
        "    frequency = []\n",
        "    while treeNode != None:\n",
        "        prefixPath = []\n",
        "        # From leaf node all the way to root\n",
        "        ascendFPtree(treeNode, prefixPath)\n",
        "        if len(prefixPath) > 1:\n",
        "            # Storing the prefix path and it's corresponding count\n",
        "            condPats.append(prefixPath[1:])\n",
        "            frequency.append(treeNode.count)\n",
        "\n",
        "        # Go to next node\n",
        "        treeNode = treeNode.next\n",
        "    return condPats, frequency"
      ],
      "metadata": {
        "id": "zVLOwQAEWwZG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Association Rule\n",
        "\n",
        "Accepts an additional optional parameter minLift (defaulting to None), which allows filtering rules based on the lift metric in addition to confidence.\n"
      ],
      "metadata": {
        "id": "H2PspKD6XGX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def associationRule(freqItemSet, itemSetList, minConf, minLift=None):\n",
        "    rules_conf_only = []  # Rules filtered by confidence only\n",
        "    rules_conf_lift = []  # Rules filtered by confidence and lift\n",
        "    total_transactions = len(itemSetList)\n",
        "\n",
        "    for itemSet in freqItemSet:\n",
        "        subsets = powerset(itemSet)\n",
        "        itemSetSup = getSupport(itemSet, itemSetList)\n",
        "        for s in subsets:\n",
        "            antecedent = set(s)\n",
        "            consequent = itemSet.difference(antecedent)\n",
        "            if not consequent:\n",
        "                continue\n",
        "            sup_antecedent = getSupport(antecedent, itemSetList)\n",
        "            if sup_antecedent > 0:\n",
        "                confidence = itemSetSup / sup_antecedent\n",
        "                # Add to confidence-only rules if it meets minConf\n",
        "                if confidence >= minConf:\n",
        "                    rules_conf_only.append([antecedent, consequent, confidence])\n",
        "\n",
        "                # Calculate lift if minLift is provided\n",
        "                if minLift is not None:\n",
        "                    sup_consequent = getSupport(consequent, itemSetList)\n",
        "                    if sup_consequent > 0:\n",
        "                        expected_confidence = sup_consequent / total_transactions\n",
        "                        lift = confidence / expected_confidence\n",
        "                        if confidence >= minConf and lift >= minLift:\n",
        "                            rules_conf_lift.append([antecedent, consequent, confidence, lift])\n",
        "\n",
        "    return rules_conf_only, rules_conf_lift"
      ],
      "metadata": {
        "id": "XNTr4Zq8XlDM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FP-growth_from_csv\n",
        "\n",
        "This function is a wrapper that applies the FP-growth algorithm to a dataset loaded from a CSV file. It processes the data, constructs an FP-tree, mines frequent itemsets, and generates association rules based on specified thresholds for support, confidence, and lift.\n"
      ],
      "metadata": {
        "id": "tVaYrIinXriy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fpgrowth_from_csv(filename, minSupRatio, minConf, minLift, has_header=False):\n",
        "    dataset = read_csv_data(filename, has_header)\n",
        "    if not dataset:\n",
        "        return [], [], []\n",
        "\n",
        "    frequency = getFrequencyFromList(dataset)\n",
        "    minSup = np.ceil(len(dataset) * minSupRatio)\n",
        "    print(f\"minSup: {minSup}\")\n",
        "    fpTree, headerTable = constructTree(dataset, frequency, minSup)\n",
        "    if fpTree is None:\n",
        "        return [], [], []\n",
        "\n",
        "    freqItems = []\n",
        "    mineTree(headerTable, minSup, set(), freqItems, dataset)\n",
        "    rules_conf_only, rules_conf_lift = associationRule(freqItems, dataset, minConf, minLift)\n",
        "    return freqItems, rules_conf_only, rules_conf_lift"
      ],
      "metadata": {
        "id": "xhXv_7bOX5u6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Function\n",
        "> Execute all of the above mentioned functions and have an output result\n",
        "\n"
      ],
      "metadata": {
        "id": "GOCqR0V7X_3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    filename = \"/content/drive/MyDrive/data/A1.csv\"\n",
        "    # Adjust this to your file's location in Google Drive\n",
        "    minSupRatio = 0.0001\n",
        "    minConf = 0.9\n",
        "    minLift = 90\n",
        "\n",
        "    # Run the FP-growth algorithm with the CSV file from Google Drive\n",
        "    freqItemSet, rules_conf_only, rules_conf_lift = fpgrowth_from_csv(\n",
        "        filename, minSupRatio, minConf, minLift, has_header=True\n",
        "    )\n",
        "\n",
        "    print(\"\\nAssociation Rules (Confidence Only, minConf = 0.9):\")\n",
        "    headers = [\"Antecedent\", \"Consequent\", \"Confidence\"]\n",
        "    table_data = [[list(rule[0]), list(rule[1]), f\"{rule[2]:.2f}\"] for rule in rules_conf_only]\n",
        "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
        "\n",
        "    # Print association rules filtered by confidence and lift\n",
        "    print(\"\\nAssociation Rules (Confidence + Lift, minConf = 0.9, minLift = 90):\")\n",
        "    headers = [\"Antecedent\", \"Consequent\", \"Confidence\", \"Lift\"]\n",
        "    table_data = [[list(rule[0]), list(rule[1]), f\"{rule[2]:.2f}\", f\"{rule[3]:.2f}\"] for rule in rules_conf_lift]\n",
        "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGBMuBXKYdEq",
        "outputId": "03f86024-83e2-4fde-814a-59d9b8af6ae0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "minSup: 4.0\n",
            "\n",
            "Association Rules (Confidence Only, minConf = 0.9):\n",
            "+---------------------+---------------------+--------------+\n",
            "| Antecedent          | Consequent          |   Confidence |\n",
            "+=====================+=====================+==============+\n",
            "| ['flower soil']     | ['fertilizer']      |         1    |\n",
            "+---------------------+---------------------+--------------+\n",
            "| ['fertilizer']      | ['flower soil']     |         1    |\n",
            "+---------------------+---------------------+--------------+\n",
            "| ['nuts']            | ['prunes']          |         1    |\n",
            "+---------------------+---------------------+--------------+\n",
            "| ['prunes']          | ['nuts']            |         1    |\n",
            "+---------------------+---------------------+--------------+\n",
            "| ['cling film']      | ['bags']            |         1    |\n",
            "+---------------------+---------------------+--------------+\n",
            "| ['bags']            | ['cling film']      |         0.95 |\n",
            "+---------------------+---------------------+--------------+\n",
            "| ['photo']           | ['film']            |         1    |\n",
            "+---------------------+---------------------+--------------+\n",
            "| ['film']            | ['photo']           |         1    |\n",
            "+---------------------+---------------------+--------------+\n",
            "| ['packaged fruit']  | ['vegetables']      |         1    |\n",
            "+---------------------+---------------------+--------------+\n",
            "| ['vegetables']      | ['packaged fruit']  |         1    |\n",
            "+---------------------+---------------------+--------------+\n",
            "| ['red']             | ['blush wine']      |         1    |\n",
            "+---------------------+---------------------+--------------+\n",
            "| ['blush wine']      | ['red']             |         1    |\n",
            "+---------------------+---------------------+--------------+\n",
            "| ['fruit']           | ['vegetable juice'] |         1    |\n",
            "+---------------------+---------------------+--------------+\n",
            "| ['vegetable juice'] | ['fruit']           |         1    |\n",
            "+---------------------+---------------------+--------------+\n",
            "| ['rolls']           | ['buns']            |         1    |\n",
            "+---------------------+---------------------+--------------+\n",
            "| ['buns']            | ['rolls']           |         1    |\n",
            "+---------------------+---------------------+--------------+\n",
            "\n",
            "Association Rules (Confidence + Lift, minConf = 0.9, minLift = 90):\n",
            "+--------------------+--------------------+--------------+---------+\n",
            "| Antecedent         | Consequent         |   Confidence |    Lift |\n",
            "+====================+====================+==============+=========+\n",
            "| ['flower soil']    | ['fertilizer']     |         1    | 2422.81 |\n",
            "+--------------------+--------------------+--------------+---------+\n",
            "| ['fertilizer']     | ['flower soil']    |         1    | 2422.81 |\n",
            "+--------------------+--------------------+--------------+---------+\n",
            "| ['nuts']           | ['prunes']         |         1    | 1174.7  |\n",
            "+--------------------+--------------------+--------------+---------+\n",
            "| ['prunes']         | ['nuts']           |         1    | 1174.7  |\n",
            "+--------------------+--------------------+--------------+---------+\n",
            "| ['cling film']     | ['bags']           |         1    |  496.99 |\n",
            "+--------------------+--------------------+--------------+---------+\n",
            "| ['bags']           | ['cling film']     |         0.95 |  496.99 |\n",
            "+--------------------+--------------------+--------------+---------+\n",
            "| ['photo']          | ['film']           |         1    |  490.7  |\n",
            "+--------------------+--------------------+--------------+---------+\n",
            "| ['film']           | ['photo']          |         1    |  490.7  |\n",
            "+--------------------+--------------------+--------------+---------+\n",
            "| ['packaged fruit'] | ['vegetables']     |         1    |  302.85 |\n",
            "+--------------------+--------------------+--------------+---------+\n",
            "| ['vegetables']     | ['packaged fruit'] |         1    |  302.85 |\n",
            "+--------------------+--------------------+--------------+---------+\n",
            "| ['red']            | ['blush wine']     |         1    |  246.91 |\n",
            "+--------------------+--------------------+--------------+---------+\n",
            "| ['blush wine']     | ['red']            |         1    |  246.91 |\n",
            "+--------------------+--------------------+--------------+---------+\n"
          ]
        }
      ]
    }
  ]
}